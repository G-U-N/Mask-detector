{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "决策树训练集正确率 91.33333333333333\nGDBT训练集正确率 92.0\nAdaBoost训练集正确率 92.66666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.ensemble import GradientBoostingClassifier  \n",
    "from sklearn.ensemble import AdaBoostClassifier  \n",
    "import matplotlib.pyplot as plt  \n",
    "import matplotlib as mpl  \n",
    "from sklearn import datasets  \n",
    "  \n",
    "iris=datasets.load_iris()  \n",
    "x=iris.data[:,:2]  \n",
    "y=iris.target  \n",
    "  \n",
    "model1=DecisionTreeClassifier(max_depth=10)  \n",
    "model2=GradientBoostingClassifier(n_estimators=100)  \n",
    "model3=AdaBoostClassifier(model1,n_estimators=100)  \n",
    "model1.fit(x,y)  \n",
    "model2.fit(x,y)  \n",
    "model3.fit(x,y)  \n",
    "model1_pre=model1.predict(x)  \n",
    "model2_pre=model2.predict(x)  \n",
    "model3_pre=model3.predict(x)  \n",
    "res1=model1_pre==y  \n",
    "res2=model2_pre==y  \n",
    "res3=model3_pre==y  \n",
    "print(\"决策树训练集正确率\",np.mean(res1*100))  \n",
    "print(\"GDBT训练集正确率\",np.mean(res2*100))\n",
    "print(\"AdaBoost训练集正确率\",np.mean(res3*100))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[10:22:17] WARNING: D:\\Build\\xgboost\\xgboost-1.2.1.git\\src\\learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[1]\ttrain-merror:0.14286\ttest-merror:0.26667\n",
      "[2]\ttrain-merror:0.14286\ttest-merror:0.26667\n",
      "[3]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[4]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[5]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[6]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[7]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[8]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[9]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[10]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[11]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[12]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[13]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[14]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[15]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[16]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[17]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[18]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[19]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[20]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[21]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[22]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[23]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "[24]\ttrain-merror:0.13333\ttest-merror:0.26667\n",
      "predicting, classification error= 0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn import datasets  \n",
    "  \n",
    "iris=datasets.load_iris()  \n",
    "x=iris.data[:,:2]  \n",
    "y=iris.target  \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, random_state=1)  \n",
    "data_train = xgb.DMatrix(x_train,label=y_train)  \n",
    "data_test=xgb.DMatrix(x_test,label=y_test)  \n",
    "param = {}  \n",
    "param['objective'] = 'multi:softmax'  \n",
    "param['eta'] = 0.1  \n",
    "param['max_depth'] = 5\n",
    "param['silent'] = 1  \n",
    "param['nthread'] = 4  \n",
    "param['num_class'] = 3  \n",
    "watchlist = [ (data_train,'train'), (data_test, 'test') ]  \n",
    "num_round = 25\n",
    "bst = xgb.train(param, data_train, num_round, watchlist );  \n",
    "pred = bst.predict( data_test );  \n",
    "print ('predicting, classification error=', (sum( int(pred[i]) != y_test[i] for i in range(len(y_test))) / float(len(y_test)) ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}